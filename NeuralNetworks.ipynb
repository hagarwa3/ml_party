{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-vs-all Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the parameters for this part of the exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 20x20 Input Images of Digits\n",
    "# 10 labels, from 0 to 9\n",
    "input_layer_size = 400\n",
    "num_labels = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading and Visualizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and Visualizing Data...\n",
      "(5000, 400) (5000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load Training Data\n",
    "print 'Loading and Visualizing Data...'\n",
    "\n",
    "data = loadmat('datasets/ex3data1.mat') # training data stored in arrays X, y\n",
    "X = data['X']\n",
    "y = data['y']\n",
    "print X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample from the MNIST Dataset\n",
    "![MNIST Sample](https://www.filepicker.io/api/file/cx0w731pSwa3xIMyGKIu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace all '10's in the y array with '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10]\n",
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "print np.unique(y)\n",
    "y_replaced = y\n",
    "np.place(y_replaced, y == 10, [0])\n",
    "print np.unique(y_replaced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions for vectorized logistic regression in one-vs-all classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# All functions from EX2\n",
    "\n",
    "def sigmoid(z):\n",
    "    g = 1 / (1 + np.exp(-z))\n",
    "    return g\n",
    "\n",
    "def computeLogisticParts(theta, X, y):\n",
    "    h = sigmoid(np.dot(X, theta))\n",
    "    pos = np.vdot(y, np.log(h)) # computes summation also\n",
    "    neg = np.vdot((1-y), np.log(1-h)) # computes summation also\n",
    "    \n",
    "    return h, pos, neg\n",
    "\n",
    "def cost(theta, X, y):\n",
    "    m, n = X.shape\n",
    "    h, pos, neg = computeLogisticParts(theta, X, y)\n",
    "\n",
    "    J = (pos + neg) / (-m)\n",
    "    return J\n",
    "\n",
    "def gradient(theta, X, y):\n",
    "    m, n = X.shape\n",
    "    h, pos, neg = computeLogisticParts(theta, X, y)\n",
    "\n",
    "    grad = np.dot((h - y), X) / m\n",
    "    return grad\n",
    "\n",
    "def costReg(theta, X, y, reg_lambda):\n",
    "    m, n = X.shape\n",
    "    temp_theta = theta\n",
    "    temp_theta[0] = 0\n",
    "    J = cost(theta, X, y)\n",
    "    J = J + (reg_lambda / (2 * m)) * (np.vdot(temp_theta, temp_theta))\n",
    "    return J\n",
    "\n",
    "def gradientReg(theta, X, y, reg_lambda):\n",
    "    m, n = X.shape\n",
    "    temp_theta = theta\n",
    "    temp_theta[0] = 0\n",
    "    grad = gradient(theta, X, y)\n",
    "    grad = grad + (reg_lambda / m) * temp_theta\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def oneVsAll(X, y, num_labels, reg_lambda):\n",
    "    m, n = X.shape\n",
    "    all_theta = np.zeros(( num_labels, n+1 ))\n",
    "\n",
    "    # Add ones to the X data matrix\n",
    "    X_ones = np.column_stack(( np.ones(m), X ))\n",
    "    print 'X_ones is ', X_ones.shape\n",
    "    \n",
    "    init_theta = np.zeros(n+1)\n",
    "\n",
    "    for i in range(num_labels):\n",
    "        y_i = np.array([1 if label == i else 0 for label in y])\n",
    "        # [theta] = fmincg (@(t)(lrCostFunction(t, X, (y == c), lambda)), initial_theta, options);\n",
    "        #res = fmin_tnc(func=costReg, x0=init_theta, fprime=gradientReg, args=(X_ones, y_i, reg_lambda))\n",
    "        res = minimize(method='SLSQP', fun=costReg, x0=init_theta, jac=gradientReg, args=(X_ones, y_i, reg_lambda))\n",
    "        theta_reg = res.x\n",
    "        print 'Class', i, 'cost = ', costReg(theta_reg, X_ones, y_i, reg_lambda)\n",
    "        all_theta[i,:] = theta_reg\n",
    "    \n",
    "    return all_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_ones is  (5000, 401)\n",
      "Class 0 cost =  0.0378434412349\n",
      "Class 1 cost =  0.0276097817247\n",
      "Class 2 cost =  0.0876765208075\n",
      "Class 3 cost =  0.0938895639083\n",
      "Class 4 cost =  0.0502609669125\n",
      "Class 5 cost =  0.061479507141\n",
      "Class 6 cost =  0.0363146199082\n",
      "Class 7 cost =  0.0442682440829\n",
      "Class 8 cost =  0.169855632643\n",
      "Class 9 cost =  0.116566352125\n"
     ]
    }
   ],
   "source": [
    "reg_lambda = 0.1\n",
    "all_theta = oneVsAll(X, y, num_labels, reg_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predictOneVsAll(all_theta, X):\n",
    "    m, n = X.shape\n",
    "    # Add ones to the X data matrix\n",
    "    X_ones = np.column_stack(( np.ones(m), X ))\n",
    "    p = sigmoid(np.dot(X_ones, all_theta.T))\n",
    "    p_max = np.argmax(p, axis=1)\n",
    "    return p_max\n",
    "    #return [1 if p >= 0.5 else 0 for p in probabilities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.9234\n"
     ]
    }
   ],
   "source": [
    "# Compute accuracy on our training set\n",
    "p = zip(predictOneVsAll(all_theta, X), y)\n",
    "results = [1 if a == b else 0 for (a, b) in p]\n",
    "print 'Train Accuracy: ', float(sum(results)) / float(len(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_layer_size = 25 # 25 hidden units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Parameters theta1 and theta2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 401) (10, 26)\n"
     ]
    }
   ],
   "source": [
    "weights = loadmat('datasets/ex3weights.mat')\n",
    "theta1 = weights['Theta1']\n",
    "theta2 = weights['Theta2']\n",
    "print theta1.shape, theta2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict classes based on pre-computed theta1 and theta2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output layer size:  (5000, 10)\n"
     ]
    }
   ],
   "source": [
    "m, n = X.shape\n",
    "# already defined, but num_labels = theta2.shape[0]\n",
    "\n",
    "# Input Layer\n",
    "a1 = np.column_stack(( np.ones(m), X )) # a1 -> (5000, 401)\n",
    "\n",
    "# Hidden Layer\n",
    "z2 = np.dot(theta1, a1.T) # z2 -> (25, 5000)\n",
    "a2_sig = sigmoid(z2) # a2_sig -> (25, 5000)\n",
    "a2 = np.vstack(( np.ones(a2_sig.shape[1]), a2_sig )) # a2 -> (26, 5000)\n",
    "\n",
    "# Output layer\n",
    "z3 = np.dot(theta2, a2) # z3 -> (10, 5000)\n",
    "a3 = sigmoid(z3).T # a3 -> (10, 5000) transposed to (5000, 10)\n",
    "print \"Output layer size: \", a3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.9752\n"
     ]
    }
   ],
   "source": [
    "# Compute accuracy of the given thetas on our neural network\n",
    "\n",
    "pred_nn = np.argmax(a3, axis=1)\n",
    "\n",
    "# Correct the index shift in the prediction (nn features are 1,2,...,9,0 but argmax gives 0,1,...,8,9)\n",
    "pred_nn_inc = pred_nn + 1\n",
    "pred_nn_corrected = pred_nn_inc\n",
    "np.place(pred_nn_corrected, pred_nn_inc == 10, [0])\n",
    "\n",
    "p_nn = zip(pred_nn_corrected, y.reshape(-1))\n",
    "results_nn = [1 if a == b else 0 for (a, b) in p_nn]\n",
    "print 'Train Accuracy: ', float(sum(results_nn)) / float(len(results_nn))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
